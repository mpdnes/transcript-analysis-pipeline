{\rtf1\ansi\ansicpg1252\deff0\nouicompat\deflang1033{\fonttbl{\f0\fnil\fcharset0 Georgia;}{\f1\fnil\fcharset0 Times New Roman;}{\f2\fnil Times New Roman;}{\f3\fnil\fcharset161 Times New Roman;}{\f4\fnil\fcharset1 Cambria Math;}}
{\*\generator Riched20 10.0.17763}{\*\mmathPr\mmathFont4\mwrapIndent1440 }\viewkind4\uc1 
\pard\tx440\tx880\tx1320\tx1760\tx2200\tx2640\tx3080\tx3520\tx3960\tx4400\tx4840\tx5280\tx5720\tx6160\tx6600\tx7040\tx7480\tx7920\tx8360\tx8800\tx9240\f0\fs22 Principles of Data Mining\par
Professor Kinsman\par
CSCI-420-01\par
September 23, 2019 \par
\par
Professor:  This is an attendance quiz.  This is a, "were you here and paying attention quiz."  I may not even collect it.  Who knows.  Depends on how much energy I have.  \par
\par
Good day for an attendance quiz!  What do you know?  Sometimes people just don't show up.  \par
\par
What is question 3?  \par
\par
Student:  What does it mean?  \par
\par
Professor:  I have no idea.  Obviously this was something written in haste.  What does it mean for?  I don't know.  Beats me.  You'll have to figure that out.  Just goes to show you that sometimes on attendance quizzes, the most important thing is your name.  But we'll go over a bunch of distances today.  You've been using distances to tell the difference between things and we just assume we know what they are.  \par
\par
I don't know.  It's probably written there but the font is white.  That's the mistake.  See if you can figure it out.  I often will make up a quiz and the answers are right there on the quiz and it's just in a white font and you can't see it.  Sometimes I accidentally white out too much and white out the question.  \par
\par
Student:  That's not even a word.  That's definitely not a word.  \par
\par
Professor:  Oh.  It's lost.  It's gone.  I have no idea what it means.  Distance between.  Sure.  It might have been a question -- I am fighting off a cold.  Sometimes somedays the most important thing about work is showing up.  I'm pretty sure I'm not that contagious because I got it from a student.  So turnaround is fair play!  That's the way it goes.  We'll go through the book today.  \par
\par
Let's see . . . there will be another homework coming out but I'm behind because I'm sick.  I was supposed to write this up yesterday but I was busy sleeping instead.  It will be something to do with data cleaning on data you have seen already.  Probably data about you, like what's your favorite cookie?  Or looking at the data, what were some issues?  The data from the obtuse quiz went through a processing path.  That path is important.  \par
\par
We took it -- ran it through a pearl script.  Everybody was given a unique identifier using a hash code.  Yay.  We converted some of the things into other things and loaded it up into Excel and sometimes Excel makes mistakes.  In fact, there was a famous mistake -- anyway, it was about 2 years ago that somebody found a mistake that everybody was doing wrong in Excel.  They were competing statistics wrong in papers.  It was a big deal and it invalidated a bunch of results.  But oh well.   \par
\par
Today we'll talk about the distance between Rochester and Buffalo, similarity and dissimilarity, and common distance metrics.  We probably won't get to them all.  What's going on Wednesday?  \par
\par
Student:  Career fair.  \par
\par
Professor:  The career circus?  Something like that?  During that time, parking is really tough.  So I think I'm just going to punt.  Especially because I'm 3 sheets to the wind.  You will be given an assignment to read.  I will post a pdf you must read.  That pdf has to do with GPS day.  Global positioning system.  That's something that tells you where you are.  The data I have collected myself, painstakingly by hand, every time I go out to RIT I turn on my GPS device and drive to RIT and then turn it off and come back and I have records.  You'll have to learn how to parse those records.  \par
\par
On your resume, you can say you worked with geospatial data.  Even if you haven't done it yet, you can say you have.  I have students who were called up for an interview because they knew something about GPS so it really helps.  So it's a tiny device that collects where you were, tells where you are, has a little smarts to it but not much, and then generates gigabytes of data.  Really stupid.  Not much to it.  \par
\par
Then you can take that device and have it talk to other devices.  It can be married to other devices that says you were here, Nick was there, or Emily was here, and they were there . . . however it goes.  These devices are coming more and more.  Tiny devices that record a lot of data that they don't even know what they're going to do with it.  They record all sorts of stuff.  What do we call these things?  Sometimes they share them over the internet.  \par
\par
They post it on a website somewhere.  What are they called, these things on the internet?  \par
\par
Student:  Internet of things.  \par
\par
Professor:  What is so funny, Carl?  \par
\par
What do we call these things?  \par
\par
Student:  Internet of things.  \par
\par
Professor:  That's right.  I don't know who made that up.  It's the same as pervasive computing.  We used to call it that but now we call it IoT and is more important with industries going online with the industrial internet of things.  They're trying, at least.  But first, a story.  Not long ago, about 2 years ago, I was walking down the first floor and I saw a poster on the wall of this woman named Malala.  I don't know who she was.  But she had a head scarf on.  What's that called?  Hijab?  Not the full burqa.  That's a different fashion statement and religious belief.  \par
\par
I didn't know who she was but I wanted to know what this kid was famous for.  \par
\par
Student:  She's an activist and she got shot by the Taliban.  \par
\par
Professor:  Because she was already famous.  She was secretly blogging for the benefit of schools.  She was blogging under an assumed identity to promote that women should be educated in Pakistan.  So that's why the Taliban tracked her down and shot her because they didn't want women to get smart.  So I found out about her and I saw, oh that's cool.  Turns out she showed up and she was going to Buffalo and I went to go see her.  So this is about that trip to Buffalo.  But first, a tangent.  It will relate to the workshop we're doing on October 6th, if you can make it.  \par
\par
Early, like February this year, my son has a skiing accident.  He got a deep cut in his left knee, and we took him to urgent care.  It was 6:45am and the doctor was a woman from Pakistan.  What would have clued me in to the fact she was from Pakistan?  She was wearing a headscarf.  I said, "I see you're wearing a head scarf.  That's obvious.  Are you from Pakistan?"  She said yes.  \par
\par
What did I say?  Did I say, "oh, huh, you're from Pakistan, you can't work on my son!  We don't need stitches!"  There are some people who would say this!  "You're not worthy to work on my son!"  I didn't say that.  Did I accuse her of not knowing anything about sewing because she's a woman?  No!  I might have said, "Wow! You have dedicated your life to helping others."  \par
\par
Somebody who came from Pakistan to the United States and was not practicing medicine.  I was impressed.  Some of these people grow up on dirt floors.  So it's important to appreciate everybody else's great strength.  I was talking about Malala because I knew about that.  It's interesting and maybe it was a coincidence, maybe it's not, but we never got charged for that visit.  There's a $500 bill out there that was never asked of us.  \par
\par
Sometimes just treat other humans like people and nice things happen.  \par
\par
When we start talking about things at the workshop, playing with jigsaw puzzle pieces, you'll see how this ties together.  Sometimes things are not always how they seem to be.  So anyway, I had to go from Rochester to Buffalo.  Anybody know how far that is?  \par
\par
Student:  64 miles.  \par
\par
Professor:  Is it?  Oh.  Yeah.  That's what people normally think.  But I could measure that some other way.  \par
\par
Student:  Using your GPS.  \par
\par
Professor:  Not 100km.  I know what you're thinking.  It's the same thing but different units.  I could measure in my GPS . . . but it could be something else.  It could be how much coffee or food I need.  Am I going to buy donuts?  No!  Donuts are yucky.  \par
\par
Guess what they call this type of store?  See, the section before this is from India and not everybody knows what they're called in the United States.  They're called convenience stores.  So there must also be inconvenience stores.  This is what they look like.  Kid sitting here and there's the shelves.  Inconvenience.  I want us to think about distances as a measure of inconvenience.  How much work -- crap -- do you have to go through to get from one place to another.  It could be how many miles you drive.  But usually there's something else, some other something that's going on.  \par
\par
It could be 64 miles or if I'm into minimizing the impact on society, which I am, I also think about is it worth me polluting this much to get from here to there to hear a famous woman talk.  And it was.  But . . . I could also be measuring the distance in right turns.  I could be measuring it in terms of lost opportunities.  How much wear and tear did I put on my car tires?  I'm spending things as I go along.  Losing tires.  There could be -- see if we're still connected -- ah ha!  That's not what I wanted.  \par
\par
Sorry, technology.  \par
\par
OK.  \par
\par
Good.  Stress.  Tickets.  It could be other detours.  I could have to deal with accidents.  Reliability trade-offs.  I had to pay a toll to get there.  I didn't even know I was paying a toll.  There's a transponder in my car that tells the thruway who I am and it uses that transponder to automatically suck the money out of our bank account.  That's a psychological distance.  That transponder means I don't have to think about the fact I'm spending money when I'm driving.  They've increased the psychological distance.  \par
\par
I had to buy all these things.  A number of left hand turns.  Wicked dangerous.  You have to wait until nobody else is coming and then you can go.  All of these things could be used to measure the tradeoffs we make when going from place A to B.  Are you with me?  How many of you drive?  \par
\par
Oh good.  We can all relate.  What's the problem with left hand turns?  \par
\par
Student:  You have to wait for traffic to be clear before you can turn.  \par
\par
Professor:  If I have a tiny car that doesn't have much power, I have to wait until nobody is coming.  I call them geriatric left turns.  I can combine them in my own way and design something that I think is really important.  It could be some weight times some distance, plus another weight times something else . . . this could be a combination of distance, gas, and time.  It's nice when these weights add up to 1, just for convenience.  It's nice to think of them all adding up to 100%.  I can choose those weights and build my own distance metric.  The thing I think is important.  \par
\par
Sometimes people know exactly which things to measure for a particular domain.  They know what's critical for them.  Some of those domain experts are people who do route planning.  How you get from place A to B.  How do you cover everybody you need to cover in a minimum amount of time or safety?  When I buy stuff on Amazon, it used to be -- now they take a whole bunch of boxes and throw them into a van and drive them.  But I liked it better when they sent it by UPS because the UPS drivers minimize the amount of fuel spent and left turns.  \par
\par
UPS drivers, because they're driven by an algorithm, they're told how to drive and what route to take, they'll take 4 right hand turns before they take a left.  They don't want to sit in traffic and wait for it to clear and lose time.  They're not delivering packages if they're sitting there.  UPS drivers do not turn left.  They are solving the vehicle routing problem.  What is that in computer science?  \par
\par
You have to go visit a lot of houses in the minimum complexity issue.  \par
\par
Student:  I'm blanking on the name.  \par
\par
Student:  Traveling salesman.  \par
\par
Professor:  Yes.  It's a rescue allocation problem all over again.  So this happens all the time.  Left turns, bad.  Got it.  \par
\par
If we have -- and this is jumping ahead -- if you have a similarity or a dissimilarity, you can convert one to the other.  A similarity is how similar things are.  If I want to know how similar -- I forgot people's names -- if I wonder to know how similar these two people are, I could compute these things.  A and E . . . they're not far away.  Vowels . . . similar.  \par
\par
Distance is how different they are in a measurable distance.  A perfect ideal distance has 3 nice properties.  This is, I have to cover this for Elana because she's in the computational math department and she knows that a proper metric difference has to be positive.  A distance between two points must be greater than 0 and symmetrical and better obey the triangle inequality.  I have a slide for all of these.  \par
\par
The distance between X and Y has to be greater than 0 for all data records.  The only time it's equal to 0 is if they're the same.  \par
\par
The distance from Andy to Emerson better be the same as Emerson to Andy.  Distance from A to B is the same as B to A.  Doesn't matter how you do it.  The 3rd really nice property of an ideal distance is the distance from X to Z is less than or equal to any other point, and then any other point back to Z.  It's the minimum distance you can possibly get.  Am I right?  Good.  \par
\par
These are ideal distances.  We hardly have ideal distances.  Today we'll look at a bunch of them and almost none of them are perfect.  But it's nice when we have them.  And when we're violating them, it's nice to violate them.  Amelia, did you have a question?  \par
\par
Which is closer, flying across the Atlantic or across the Pacific?  \par
\par
Student:  I'm not brushed up on my geography.  \par
\par
Professor:  We know you're named after Amelia Aerhart.  Why is she famous?  \par
\par
Student:  Flying around the world.  \par
\par
Student:  She almost flew around the world.  \par
\par
Professor:  So this I was to address because it's a common -- we have to unlearn some common misnomers.  \par
\par
Student:  She was famous before getting lost.  She crossed the Atlantic.  \par
\par
Professor:  Yes.  Exactly.  We have in our midst somebody that was named after her.  When you do that, you find that it's much easier to fly across the Atlantic than the Pacific, because why, Amelia?  \par
\par
Student:  Could you repeat the question?  \par
\par
Professor:  Why is it easier to cross the Atlantic?  \par
\par
Student:  It's a shorter distance.  \par
\par
Professor:  Because of the trade winds!  That's right.  If you have winds coming behind you, you just have to hop up, stay aloft.  But flying across the Pacific you fly into the wind.  Distances are not easy.  Suddenly they're complicated.  What kinds of distance do we have?  \par
\par
[Professor reading: PowerPoint.]  \par
\par
We're going to talk about all of these.  \par
\par
Oh boy.  This is just some of them.  I widdled it down.  So this is the distance we all know and love.  When we were in 9th or 3rd grade we learned this stuff.  The distance between two points, I have two vectors, one is a vector of \i\f1 x\i0\f0  and it has all these attributes.  \par
\par
So we can define the distance between them in the euclidean sense as the difference between every single attribute.  I get the difference for all of them, square it, add them all up, and then take it to the \f1\'bd\i  \i0\f0 power.  That's what we all know and love.  Don't fall asleep.  This is called the L\sub 2\nosupersub  norm.  This is just the convention.  Elana would know more about why we use L than I do.  Where's the 2?  There's the 2.  \par
\par
That's the euclidean distance.  The L\sub 2\nosupersub  norm.  There's a conference coming up on the 4th of October and if you go you should know what the L\sub 1\nosupersub  and L\sub 2\nosupersub  norm.  Hey, there's no twos up there!  What do we have?  Ones!  You can see from parallel building what's going on.  It's the difference of every attribute and take the absolute value, raise it to the 1st power, add up the attributes, and take the 1st root.  You don't take a root.  That's what the 1st root does.  This is the L\sub 1\nosupersub  norm.  \par
\par
I drew a 1 here and here because it's very easy for people to write this out without those 1s and you don't understand why this is called the L\sub 1\nosupersub  norm so I like to put it in there at least the first time you see it.  So this is a distance that's familiar to you if you're in New York City.  Also called Manhattan.  It's a very laid out city.  You have streets and avenues.  You go up blocks.  Sometimes this is the taxi cab distance.  \par
\par
OK.  You could write that that way or ignore all the 1s and it boils down to this.  This is what books say.  You're thinking, where are the 1s?  That's why I threw the 1s in so you know where they came from.  \par
\par
You want to go from point A all over to here to highline park.  I think there's a good bookstore over here.  In order to get there you have to go down and over and down and over and down and over, or you can go over and down.  But it's the same number of blocks.  As long as you're not cheating.  This is the Spider-Man distance.  It works for him, but not for me.  I have a new distance to think about.  \par
\par
Sometimes we call this as the crow flies.  That would be the L\sub 2\nosupersub  distance and the purple line is the L\sub 1\nosupersub  distance.  You have to stay on the grid-lines when using the L\sub 1\nosupersub  distance.  I could climb over all the desks to get to the back corner, but that would be awkward so I have to take different routes.  But it's the same distance to go.  \par
\par
I have these two vectors like this, we come up with something called the generalized Minkowski Norm.  We take the absolute value to make them not negative, and raise them to the p power.  We add them up, and take the p-ith root.  I've seen papers where they use 1.5 Minkowski distance.  I don't know why but it worked for them.  But that's a generalized Minkowski norm.  I assume he was a mathematician.  \par
\par
Not William -- Blake?  \par
\par
Student:  Is there a real world equivalent to the L\sub 3\nosupersub  norm?  Like if you were trying to travel from point A to B.  \par
\par
Professor:  Not outside the science fiction universe.  Like hyper space.  We'll get into space with support vector machines.  They warp space.  If I had a wonderful analogy, or a good metaphor, I would use it to teach but I don't.  But that's the math up there to help them solve the problem better.  Parker, have a question?  \par
\par
Student:  No.  \par
\par
Professor:  What if I put in 0 there?  That's cool.  I have two vectors, different attributes, take this thing, minus that thing . . . what's anything to the 0th power?  Generally 1.  But there's one exception.  0!  Perfect.  The only time you take something and raise it to the 0th and get something other than 1 is when it's the same thing.  \par
\par
So it's how many attributes are different from one vector to the other.  It's the sum of the times and -- how many attributes are different?  That's the L\sub 0\nosupersub  norm and the intuition of the norm.  \par
\par
What other things can we plug in?  Think mathematicians.  Fatima.  What would you go for?  The sky is the limit.  Think like, go infinitely far.  What would you throw in?  Infinity!  Yes, that's right!  That's the supremum norm.  When you push this in, the math and how you take these limits is beyond me.  I was not good at proving limits.  The whole point is the L-infinity norm is the biggest that they're in.  It doesn't make sense to use this if the units are all different.  You want it to make sense.  \par
\par
Some different units that can be compared to each other as you're going along.  Make sense?  The Hamming Distance.  This is usually known very well by computer scientists.  I learned this freshman year but I had a different program.  This is the number of bits that are different between any two vectors as you are going along.  \par
\par
So it's used for detecting changes in binary attributes whether the gene is there or not there.  Things of that nature.  So it's 1 of these general cases with the Minkowski norm and we'll see that in a second.  This might be on the midterm.  What's the general form of the Minkowski Norm?  The L\sub P\nosupersub  norm?  Or the L\sub 5\nosupersub  norm?  So you should know that.  Which of these is the euclidean distance?  \par
\par
Right?  Which is the L\sub 1\nosupersub  norm?  Oh, police!  They wrote this cute program in Toronto.  Toronto is a gridded city just like Manhattan.  You could go around the parks so there were some exceptions.  Because it's gridded, the police have a situation where if a guy breaks into someplace somewhere, they can say the crime happened here and they can figure out how far that person must have gone.  This is Toronto.  The Mounties always get their man.  That's what they say.  This is nice because the women don't rob anything.  It's Canadia.  They're nice to each other.  \par
\par
They have a way of plugging in where the crime happened and figuring out the search radius and how big of a safety net they have.  \par
\par
I learned about that on a program show called Numbers.  Which is before your time.  But it was used to solve mysteries using pattern recognition and data mining.  I watched every episode.  \par
\par
Which distance did the police use?  They used the Manhattan distance when building that program.  So we discussed some distances, the Minkowski, infinity . . . what would the L\sub 3\nosupersub  be?  You just plug 3 in.  You're good.  \par
\par
I want to mention this.  There's a guy named Minkowski and there was somebody who named the island of Manhattan, Manhattan.  Probably Native Americans.  There's another guy from Indian named Mahalanobis.  And these words all begin with the letter 'm'.  Make sure you know the difference between them.  You want to be able to identify them and get the right distance.  Just watch out that somebody happened to name all these things with the letter 'm.'.  Andrew, what's your favorite cookie?  \par
\par
Student:  Peanut butter.  \par
\par
Professor:  OK.  Carl?  I have to keep track of Carls.  What's your favorite cookie?  \par
\par
Student:  Chocolate chip.  \par
\par
Professor:  OK.  I'll make a record here for Carl with a 'C' and I'm going to go off PowerPoint here.  We could have something that says, Carl, Chocolate Chip, Karl -- what's your favorite cookie?  \par
\par
Student:  Snickerdoodle.  \par
\par
Professor:  I can't even spell that.  Snickers.  That what he likes.  And Andrew likes peanut butter.  I could do it this way.  Oh, yeah.  We could keep going but the distance between peanut butter and chocolate chip versus snickerdoodle, that's a hard distance to compute and it's hard to tell as we're going around.  So a trick they use is they take the variables that the value could take on and write them across the board.  \par
\par
Chocolate chip.  Snickerdoodle . . . peanut butter.  Macadamia nut.  \par
\par
Amelia?  \par
\par
Student:  Sugar.  \par
\par
Professor:  Sugar cookies.  Sure.  OK.  So now we take each person here . . . Karl, Andy, Carl, Amelia -- I can't spell.  Carl wanted chocolate chip so we put a 1 there.  He is not allowed to like any of these other cookies.  OK?  We are taking that one categorical value and breaking it up into a bunch of binary values.  We're imposing a rule that they must be exclusive of each other.  You can't like chocolate chip and macadamia nut at the same time.  \par
\par
Andy likes peanut butter.  He cannot like anything else.  Carl doesn't like -- oh he likes snickerdoodles -- but a whole bunch of 0s.  And Amelia liked sugar.  She's over here . . . OK . . . you with me?  \par
\par
Now this is called one hot coating.  The one bit that goes on is the hot bit.  This is a way of taking categorical data and converting it into binary data and I can compute the difference between different types of people.  Anybody else like chocolate chip?  OK.  Emily.  Thank goodness.  Somebody else likes chocolate chip.  And Gordon, I think I saw him raise his hands.  \par
\par
I get tired of writing 0s.  I'm getting dizzy.  This is called one hot coating.  Look at all these vectors!  There's a problem here though.  Andy and Carl, look at all these 0s they have in common!  Lots of them.  This same thing -- this is for chocolate chip cookies but it also works for things like groceries.  Do you go grocery shopping?  Do you buy groceries?  I don't know.  Maybe I get free food from RIT.  There's an app for that.  \par
\par
When you went shopping last did you buy bread?  I didn't.  Bread just doesn't -- did you buy cat food?  \par
\par
Student:  Yeah.  I have two cats.  \par
\par
Professor:  Oh wow.  OK.  Do you have kids?  \par
\par
Student:  No.  \par
\par
Professor:  You didn't buy diapers?  \par
\par
Student:  Maybe for a cat.  [Class laughing.]  \par
\par
Professor:  Diapers for a cat?  OK so -- I'm trying to get all these things you don't buy.  You probably didn't buy beer.  \par
\par
Student:  I bought it.  [Class laughing.]  \par
\par
Professor:  No way.  I'm trying to come up with things that -- \par
\par
Student:  Dog food?  \par
\par
Professor:  You don't have a dog, right?  There's all these things.  The problem that usually happens is that there are 100s of thousands of things we both didn't buy together.  You didn't buy cottage cheese.  \par
\par
Student:  I bought that . . . [Class laughing.]  \par
\par
Professor:  OK . . . I'm not having good lucky with this.  Usually this is a no brainer because students don't buy many groceries.  But you could go on and on about things people don't buy in common.  She apparently buys a lot more groceries than I do.  But Amelia, there's no way she bought power bars.  And I didn't buy them.  So we have that in common.  There's all these 0s you have in common.  That's a problem for data mining and we have to figure out how all these 0s in common can make vectors look similar.  \par
\par
So we're going to talk about the simple matching coefficient.  \par
\par
We mentioned we could convert distances to similarities.  What if it's not in the range of 0 to 1?  If it is, this is the formula.  This gets me a similarity metric.  Yahoo.  Good.  What if the distance is like, 1000?  There's 1000 bits and it will be different, how do we fix that?  \par
\par
Student:  You could normalize it.  \par
\par
Professor:  Perfect!  We take that distance that goes up to 1000 and divide by our maximum value.  Now I get a similarity that's 1 minus that distance divided by the distance maximum.  \par
\par
I think that's a little out of place but it relates.  Here's the Hamming Distance you should be somewhat familiar with.  I have two vectors here.  [Professor reading: PowerPoint ]  \par
\par
So now we're going to look at 4 different types of switches that could possibly happen for these bits.  F\sub 01\nosupersub  is the number of attributes where it goes from 0 to 1 from X to Y.  To find that, we look for a 0 on the top and a 1 below.  There's one there!  We have a 0,1 over here, and there's another one.  We have two 0,1s.  \par
\par
Similarly, 1,1 is where it was 1 and it stays 1.  Got it?  So the Hamming Distance is the sum of f\sub 10 \nosupersub + f\sub 01\nosupersub .  But the problem with the Hamming Distance is that it doesn't take into account how long the vectors are.  If we take all of our cookies and our breakfast drinks and hot coat them . . . we get a vector that's about 1000 bits long.  So you want to have some way -- considering the lengths of those bits.  The simple matching coefficient tries to take into account the total number of attributes in the vector.  It's the number of matching attributes divided by the length of the vector.  But it counts things that are present and absent, equally.  It's normalizing by the length of the vector.  It records what people bought, or didn't buy . . . \par
\par
The Jaccard is kind of similar except it only considers attributes that are present in at leaset one of the vectors.  Neither of us bought amaretto.  It's a flavoring for cooking.  Right?  You didn't buy that.  Did you buy ginger?  \par
\par
Student:  Yes.  \par
\par
Professor:  Oh shit.  Wow, she buys a lot.  I didn't buy ginger.  That's how it goes.  The Jaccard coefficient says it has to be present in at least one of those two people before we start counting them.  Let's look at an example of a simple matching coefficient.  \par
\par
Same vectors, same numbers.  The simple matching coefficient is all the bits that are the same . . . divided by the length of the total vector.  It would be \f1 (5+1)\i  \i0\f0 divided by all of them.  It's 9.  6 divided by 9 -- it's \super\f1 2\nosupersub\f2\u8260?\sub\f1 3\nosupersub .\i  \i0\f0  With me?  \par
\par
Pickles?  Did you buy pickles?  No?  \par
\par
Student:  For hot dog.  \par
\par
Professor:  What?  I keep trying to think of something.  This is everything that's similar divided by the whole length.  The Jaccard coefficient says only consider the ones that are common and both bought.  She may have bought pickles, but I didn't, so it won't count.  That's the 1,1s.  We both bought ginger, that's a 1,1.  In this case there's only 1 bit that's the same between those vectors and on divided by all of the attributes that are present in at least one of them.  \par
\par
The Jaccard coefficient ignores all those 0,0s.  It's normalized -- instead of normalizing by 9, we normalize so it goes to \f1\'bc\i  \i0\f0 instead of all the other oddball things.  Still awake?  \par
\par
Student:  Luke.  SMC does have the double 0s, and Jaccard doesn't, right?  \par
\par
Professor:  Yes.  OK.  Questions?  Comments?  We'll just have to play with these and go along as we go along.  \par
\par
Once upon a time, a long time ago, we had this thing called trigonometry.  It's not hard.  But we can use it to find how similar things are.  This is a cosine.  This is 0.  Where's the cosine 0?  It's at like 90\'b0.  Hey, there it is.  It's 0 there.  And at minus 90\'b0.  At 0, the cosine angle between two vectors is 0 and the 0 goes up to 1.  That means they're similar if they're pointing in the same direction.  \par
\par
If I take my two unit vectors and I look at the angle between them, I can figure out how similar they are by the cosine of the angle between them.  But we don't have to worry about that because -- \par
\par
Student:  The distances are positive.  \par
\par
Professor:  Right.  We don't have to generally run around and bump into those.  Here are our two vectors.  X.  Y.  In as many dimensions as we want.  It could be 1000 dimensions.  The angle between them, as it gets bigger, the cosine goes down.  In terms of a dot product, we can define X dot Y, that's one vector dotted onto the other one, which is really fast for a computer to do.  You just say, 1 times 0 -- whatever they are.  It's equal to the magnitude of X times the magnitude of Y and the cosine of the angle between them.  \par
\par
Oh.  So rearranging a bit, and taking the magnitudes I can divide by the length of those two vectors.  Easy as cake.  It works in as many dimensions as you need it to.  If you have a book that has a whole bunch of words in it, you put a 1 in there if the word is in there.  You put a 0 if the word never occurs.  I have a book on weightlifting.  I go to the gym and I lift weights.  Versus when I am doing gymnastics.  I go to the gym and do gymnastics.  The word gym would show up in both of them.  \par
\par
The cosine in between is often used for text.  If the two vectors are in the same direction, the dot product is one.  As they get close to each other, it goes up to one.  Orthogonal means perpendicular in more than two dimensions.  3D, they're orthogonal and perpendicular in all directions.  \par
\par
The nice thing about this is that it's continuously differentiable.  People who like derivatives like to take those and get smooth derivatives.  I'm picking on the computational mathematician.  It's often used for documents.  \par
\par
Somebody in here is named Liam.  Are you Liam?  \par
\par
Student:  I'm Nick.  \par
\par
Professor:  Liam is in my other class.  He has similar hair to you.  I'm sure he'll shave before the career hair and I'll tell the difference between you.  So Nick writes an essay.  Cohen writes an essay.  We want to see if they're the same.  There's a program that does that.  One of the things they do is build up a dictionary of things that are used and compute the cosine between them using the dot product formula.  \par
\par
If the same words show up multiple places, then it says, Ah-ha!  There's an issue here.  You can use that to figure out how similar things are.  These are diagrams.  That has two vectors that are perpendicular and the cosine is 0.  It's hard to see but the blue vector is on top of the red.  But they're both unit vectors and one is on top of the other and the cosine is therefore 1.  \par
\par
As they get further apart, the cosine drops off.  If they can be negative, then you have negative situations showing up.  It only goes up to minus 1 if they're going in opposite directions.  Not likely.  \par
\par
If it works for books, it works for spam detection.  It was really a big problem about 10 years ago.  Now it's pretty much solved.  Google has clever techniques.  They have fake accounts and wait to see what shows up there.  All kinds of stuff there.  OK.  It's not great for genetic sequences.  It's questionable for shopping cart analysis.  Why wouldn't I use this for genetic sequences?  Carl?  \par
\par
Student:  There's a small domain of words that could be used in genetic sequences.  There's only so many letters used so they repeat a lot.  \par
\par
Professor:  I make amino acids when I'm not even thinking about it.  So do mice.  So do giraffes.  We generate the same ones which means our DNA is the same.  About 99% of my DNA is the same as a mice.  Which is weird.  When you think about it.  It's even weirder that 97% of my DNA is the same as a string bean.  So you don't want to use it for genetic sequences.  They have their own things.  Cross correlation coefficients.  I love these.  \par
\par
This is one of my most important powerful tools.  It has the nice intuition.  Basically, how often -- how much do two variables go up and down together?  So I've got a calorie intake.  When I eat more, my weight goes up.  I'm trying to figure out what causes my dog to go into distress.  I find that when I feed him too much meat, he goes and lies down.  He has a hard time digesting it.  I start to do these cross correlation coefficients.  Your brain does that automatically.  \par
\par
If you eat something, and you get sick the next day, your brain associates the thing you just ate as the thing that made you sick.  There's a famous -- anyway, our brains are always doing cross correlation coefficients.  That's what artificial neural networks do.  It's actually correlational.  Don't tell anybody else.  They don't know the difference.  It helps to have some math every so often.  \par
\par
Oh, here's some math.  \par
\par
It's some signal \i\f1 s\i0\f0  and some signal \i\f1 t.\i0\f0   Two variables I'm measuring.  If I got a positive value -- let's see what else we have.  \i\f1 s\i0\f0  is the signal.  \f3\lang1032\'ec\sub\i\f1\lang1033 s\nosupersub  \i0\f0 is the average sub value.  This is every single entry.  As you're going through those signals, this is one value, that's the next one, so \i\f1 k\i0 ,\i  k\i0 ,\i  \i0 2,\i  \i0 2,\i  \i0 3,\i  \i0 3,\i  \i0\f0 and you go along.  It's normalized by sigma \i\f1 s.\i0\f0   This is normalized by the standard deviation of the second signal, \i\f1 t.\i0\f0   It turns out that this form -- I think it's called an inter-product.  Elana, can you help me out?  Is this inner or outer?  \par
\par
I think it's inner.  It can only go between minus 1 and 1.  That's wonderful!  I can compare the cross correlation coefficient between two things and two other things and still know what's important or not.  I love the cross correlation coefficient.  I find this, that, and add them up, and divide by \i\f1 n.\i0\f0   If it's positive, that means in general when \i\f1 s\i0\f0  is above its mean you get a positive value and \i\f1 t\i0\f0  is also above its mean and that also gives you a positive value.  \par
\par
Johnathan, how else can I get a positive value?  \par
\par
If \i\f1 s\i0\f0  is above its average value, and so is \i\f1 t\i0\f0  that gives you positive values.  If they're both positive, in general, then you get a positive cross correlation coefficient.  If they're both negative, you get a negative times a negative, so . . . they both go up above their average and below their average at the same time.  That gives you a positive cross correlation coefficient.  I have friends in the statistics department and they're so familiar with this, they can't explain it in English.  \par
\par
This is the simple deep understanding of what the cross correlation coefficient tells me.  If it goes negative, then usually when one is up the other is down or vice versa.  They go in opposite directions.  The more I exercise the less I weigh.  Or vice versa.  Depending on how you want to look at it.  \par
\par
Any questions? \par
\par
What are we normalizing?  I often write this wrong because the standard deviation needs the \i\f1 n \i0\f4\u8722?\i\f1\lang1033  \i0 1\f0  but this is another good formula to be able to right out.  To say you have this intuition.  \par
\par
Here's some graphics for it.  If it's negative, as \i\f1 x\i0\f0  goes up, \i\f1 y\i0\f0  goes down.  As it becomes more towards 0 . . . once you get there it's a big blob.  As it starts going up and becoming more positive, now you have a nice line.  OK?  \par
\par
Positive means as one goes up, the other goes up.  Positive cross correlation coefficient of 1 means they're essentially the same signal.  A modified form of the other.  Cool.  That's a good thing to remember.  \par
\par
We went all the way up to mutual information.  This is a good stopping point.  I'm going to give you GPS data.  You need to be able to parse it.  \par
\par
You can use any package to parse it.  There are packages for Python you can use.  I like to do it myself.  I like to write my own libraries for doing things.  So I'm going to give you the GPS data from my house to here and from here to my house.  I know the best route, but I want you to find that.  Also the best route, the best time I should be leaving, and we're going to need to find the waypoints.  As you go from place A to B -- where are the options you can make changes?  We call those turns.  Or stop signs.  What are the issues?  \par
\par
What do we want to minimize?  Ultimately the time.  Maybe I want to minimize how often I'm stopped at a stop light.  Depending on when I leave I'll get all the busses coming back from school and I have to stop for 5 minutes as all the busses go through.  There's nothing I can do about it.  But there's other times I can do other things as I'm going along.  So you get to play with this data.  I'll trust you with my vulnerable self.  I'll let you know where I live.  \par
\par
It's on the internet!  You can figure it out.  It's not a big deal.  It'll be fun.  You will have to work together in teams.  I know that can be hard for some of you.  But ultimately it might be the most important thing you do at RIT.  Learning to work in teams.  OK?  Honestly.  \par
\par
I will not see you Wednesday.  Go get a job.  I'll see you next Monday.  \par
\par
Take a pile of these.  I want to see who's here today.  So write your name on the top.  \par
}
 